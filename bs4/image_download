from urllib.request import urlopen
from urllib.parse import quote_plus
from bs4 import BeautifulSoup

baseurl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='
searchterm = input('검색어를 입력하세요: ')
url = baseurl + quote_plus(searchterm)

html = urlopen(url).read()
soup = BeautifulSoup(html, 'html.parser')
img = soup.find_all(class_='_img')


n = 1
for i in img:
    imgurl = i['data-source']
    with urlopen(imgurl) as f:
        with open('./img/' + searchterm + str(n) + '.jpg', 'wb') as h:
            img = f.read()
            h.write(img)
    n += 1
    print(imgurl)

print('다운로드 완료')

=====================================
## 웹툰 이미지 다운로드해서 경로 지정하여 저장하기

from bs4 import BeautifulSoup
from pprint import pprint
import requests, re, os
from urllib.request import urlretrieve

## 저장 폴더를 생성하기
try:
    if not (os.path.isdir('image')):
        os.makedirs(os.path.join('image'))
except OSError as e:
    if e.errno != errno.EEXIST:
        print("폴더 생성 실패!")
        exit()


html = requests.get('https://comic.naver.com/webtoon/weekday.nhn')
soup = BeautifulSoup(html.text, 'html.parser')
html.close()

data_list = soup.findAll('div',{'class':'col_inner'})

li_list = []
for data1 in data_list:
    li_list.extend(data1.findAll('li'))

for li in li_list:
    img = li.find('img')
    title = img['title']
    img_src = img['src']
    title = re.sub('[^0-9a-zA-Zㄱ-흻]','',title) ## import re로 특수문자가 있을시에는 빈칸으로 내버려두기
    print(title, img_src)

    urlretrieve(img_src, './image/' + title + '.jpg') # 주소, 파일경로 + 파일명 + 확장자
